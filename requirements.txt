fastapi==0.104.1
pydantic==2.5.0
python-multipart==0.0.6
python-dotenv==1.0.0

# Note: uvicorn is not needed on Vercel (Vercel runs FastAPI automatically)
# For local development, install separately: pip install uvicorn[standard]
# mangum is also not needed on Vercel (zero-config FastAPI)

# LLM provider (install to use LLM, otherwise uses mock)
# litellm supports OpenAI, Anthropic, Cohere, Google, and many more
# Install: pip install litellm
# litellm>=1.0.0

# For Langfuse integration (optional - for LLM observability)
# langfuse>=2.0.0

